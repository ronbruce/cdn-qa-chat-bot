{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "\n",
    "# Enables tracing for LangSmith or LangChain's internal operations, which could log detailed traces for debugging purposes.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# Enables tracing for LangSmith or LangChain's internal operations, which could log detailed traces for debugging purposes.\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables from .env file.\n",
    "load_dotenv()\n",
    "\n",
    "# Load API key from environment variable.\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    log.error(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "    raise ValueError(\"OPENAI_API_KEY not set in the environment.\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langsmith/client.py:322: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "\n",
    "example_messages\n",
    "\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_agent() -> str:\n",
    "    \"\"\"Get user agent from environment variable.\"\"\"\n",
    "    env_user_agent = os.environ.get(\"USER_AGENT\")\n",
    "    if not env_user_agent:\n",
    "        log.warning(\n",
    "            \"USER_AGENT environment variable not set, \"\n",
    "            \"consider setting it to identify your requests.\"\n",
    "        )\n",
    "        return \"DefaultLangchainUserAgent\"\n",
    "    return env_user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a strainer to filter the HTML content.\n",
    "# The `bs4.SoupStrainer` is configured to retain only the elements with the classes \"post-title\", \"post-header\", and \"post-content\".\n",
    "# This focused extraction ensures that only the necessary information for LangChain processing is captured, eliminating extraneous data.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "\n",
    "# Initialize the WebBaseLoader.\n",
    "# This object is responsible for fetching the content of the specified webpage and applying the filtering defined by the `bs4_strainer`.\n",
    "# It allows us to retrieve only the desired sections of the webpage while setting a custom User-Agent header to mimic a standard web browser request.\n",
    "loader = WebBaseLoader( # Document loader class\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",), # Source \n",
    "    bs_kwargs={\"parse_only\": bs4_strainer}, # Converts to standadize format for processing by LangChain\n",
    "    requests_kwargs={\"headers\": {\"User-Agent\": get_user_agent()}}\n",
    ")\n",
    "\n",
    "# Load the Document from the WebBaseLoader.\n",
    "# The `loader.load()` method retrieves the webpage content and applies the previously defined filtering.\n",
    "# The resulting documents are stored in the `docs` variable, which contains the extracted data ready for processing with LangChain.\n",
    "docs = loader.load()\n",
    "\n",
    "# Print information about the extracted content.\n",
    "# This snippet outputs the length of the extracted content (in characters) and displays the first 500 characters.\n",
    "# This verification step helps ensure that the extraction process was successful and that the expected data is captured.\n",
    "# print(len(docs[0].page_content))\n",
    "# print(docs[0].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 7056}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RecursiveCharacterTextSplitter to break down documents into manageable chunks.\n",
    "# We set chunk_size to 1000 characters, with an overlap of 200 characters to maintain context between chunks.\n",
    "# This ensures that each chunk is small enough to fit into the context window for processing (e.g., by a model like GPT).\n",
    "# The add_start_index parameter is set to True, so we can track where each chunk starts in the original document.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "\n",
    "# Split the input documents into smaller chunks for processing using the text splitter.\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Store the embedded representations of the document chunks in a Chroma vectorstore.\n",
    "# This allows for efficient similarity searches or embedded queries in downstream tasks.\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Check the length of the content in the first chunk to ensure it's within the expected chunk size.\n",
    "len(all_splits)\n",
    "\n",
    "# Get the number of chunks created from the document splits.\n",
    "len(all_splits[0].page_content)\n",
    "\n",
    "# Retrieve metadata (such as source or chunk index) from the 11th chunk to check for useful information.\n",
    "all_splits[10].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"What are the approaches to Task Decomposition?\")\n",
    "\n",
    "len(retrieved_docs)\n",
    "\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
